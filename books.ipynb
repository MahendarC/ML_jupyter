{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ecfbab-7e4e-4159-933a-94ffe90afe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas  as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70217fe-99e1-47be-b0eb-fe6e188fceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://books.toscrape.com/catalogue/page-1.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afde4102-ce2d-44c0-b71c-3281826483a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = requests.get(url)\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8951c12-37c1-4b20-bdd4-78df27483813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup  =  BeautifulSoup(r.content, 'html')\n",
    "#print(soup)\n",
    "#ol  =  soup.find('ol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31750903-1ba1-4bd8-b761-593d74b46186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles = ol.find_all('article', class_ = 'product_pod')\n",
    "#print(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8090cb87-6510-4715-a18c-8f8c7b2c329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "books  = []\n",
    "\n",
    "for i in range(1,5):\n",
    "    url = f'https://books.toscrape.com/catalogue/page-{i}.html'\n",
    "    r = requests.get(url) \n",
    "    soup  =  BeautifulSoup(r.content, 'html')       \n",
    "    ol  =  soup.find('ol')\n",
    "    articles = ol.find_all('article', class_ = 'product_pod')      \n",
    "\n",
    "\n",
    "for article in articles:\n",
    "    image = article.find('img')\n",
    "    title = image.attrs['alt']\n",
    "    #print(title)\n",
    "    star = article.find('p')\n",
    "    #print(star)\n",
    "    star = star['class'][1]\n",
    "    #print(star\n",
    "    price = article.find('p', class_ = 'price_color').text\n",
    "    #print(price)\n",
    "    price = float(price[1:])     #price[1:]\n",
    "    #print(price)\n",
    "    books.append([title, price, star])\n",
    "\n",
    "#print(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55e0634-700d-4b86-85a9-1f7702cdb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(books, columns= ['Title', 'Price', 'Star Rating'])\n",
    "df.to_csv('books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3f3a2-f770-4d5f-bb98-4c34bfdad489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866d7f7-2606-44d1-b406-8333eb6f7e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the list to store book data\n",
    "books = []\n",
    "\n",
    "# Loop through pages 1 to 5\n",
    "for i in range(1, 6):\n",
    "    url = f'https://books.toscrape.com/catalogue/page-{i}.html'\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if r.status_code != 200:\n",
    "        print(f\"Failed to fetch page {i}. Status code: {r.status_code}\")\n",
    "        continue\n",
    "    \n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    ol = soup.find('ol')\n",
    "    articles = ol.find_all('article', class_='product_pod')  \n",
    "    \n",
    "    # Loop through all articles on the page\n",
    "    for article in articles:\n",
    "        image = article.find('img')\n",
    "        title = image.attrs['alt'] if image else \"No Title\"\n",
    "        \n",
    "        star = article.find('p')\n",
    "        star = star['class'][1] if star and len(star['class']) > 1 else \"No Star Rating\"\n",
    "        \n",
    "        price = article.find('p', class_='price_color').text\n",
    "        price = float(price[1:])  # Remove currency symbol and convert to float\n",
    "        \n",
    "        # Append the book details to the list\n",
    "        books.append([title, price, star])\n",
    "\n",
    "# Print the extracted data\n",
    "for book in books:\n",
    "    print(book)\n",
    "\n",
    "# Optional: Save the data to a CSV file\n",
    "import csv\n",
    "with open(\"books_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Price\", \"Star Rating\"])  # Header\n",
    "    writer.writerows(books)\n",
    "\n",
    "print(\"Scraping completed. Data saved to books_data.csv.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d74cda-32ef-4c84-90a7-11f790d42697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
